---
title: "Hospital Analysis"
format: html
editor: visual
---

## Design and Data Collection

#### Data Collection

This project aims to analyze hospital survey data to determine what effects a hospital's quality. The hospital data that will be used was retrieved from the Centers for Medicare and Medicaid (CMS) [website](https://data.cms.gov/provider-data/dataset/dgck-syfz#data-table "CMS Website Link"){.uri}. This data was accessed on April 10th, 2025 and contains data from 2023 - 2024 from a multitude of different hospitals. This data contains three important metrics: star rating, answer percentage, and linear mean value. Of these metrics, the star rating is a 1-5 star rating given by the CMS as part of their initiative to make their Compare Web sites more intuitive. The answer percentage is the distribution of answers within each question. Most of the questions have "Always", "Usually", and "Sometimes or Never" as possible answers. The linear mean value is the metric that will be used for this analysis. This metric is an adjusted score accounting for patient mix, survey mode, and quarterly weighting. More details can be found [here](https://www.hcahpsonline.org/globalassets/hcahps/star-ratings/tech-notes/april_2025_star-ratings_tech_notes.pdf "CMS Technical Documentation"){.uri}.

#### Design

Before we create the model, we must first clean the data. Since only survey data is being considered, location data will not be included in this analysis. After isolating the linear mean values, we will fit a model using principal component analysis. Since our goal is inference, we already know we want to include all components, and we are not evaluating model predictions, we will not be creating a holdout set. After the model is created, we will look at the p-values of each component to determine how significant each component is.

## Packages Used In This Analysis

```{r}
#| label: load packages
#| message: false
#| warning: false
#| echo: false

library(here)
library(tidyverse)
library(tidymodels)
library(janitor)
library(gt)
```

| Package                                                                   | Use                                       |
|-----------------------------|-------------------------------------------|
| [here](https://github.com/jennybc/here_here)                              | to easily load and save data              |
| [tidyverse](https://www.tidyverse.org/)                                   | to perform common data science techniques |
| [tidymodels](https://tidymodels.tidymodels.org/)                          | to create models                          |
| [janitor](https://www.rdocumentation.org/packages/janitor/versions/2.2.1) | to clean "dirty" data                     |
| [gt](https://gt.rstudio.com/)                                             | to create tables                          |

## Data Massaging

```{r}
#| label: Import the dataset
#| warning: false
#| message: false
#| echo: false

here::i_am("hospital_analysis.qmd")

hospital <- read_csv(here::here("Data/HCAHPS-Hospital.csv"), na = c("Not Applicable", "Not Available"))

```

Since we will not be using location data, we will remove it from our dataset.

```{r}
#| label: Filter the dataset for relevent information

hospital <- hospital |>
  clean_names()

hospital_1 <- hospital |>
  select(
    !c("address", 
       "city_town",
       "telephone_number", 
       "hcahps_answer_description",
       "state", 
       "zip_code", 
       "county_parish") # remove all location data
  )

```

Because of the layout of the data, we have a lot of *missing* data in our three `metric columns`. This is the case since each entry in our `question column` is specific to a single metric.

```{r}
#| label: Missing data table

hospital_1_missing <- head(hospital_1) |>
  select(hcahps_question, 
         patient_survey_star_rating, 
         hcahps_answer_percent, 
         hcahps_linear_mean_value)

gt(
  hospital_1_missing,
  rowname_col = "hcahps_question"
) |>
  tab_header(title = "Glimpse of Missing Data") |>
  tab_source_note(source_note = "2024 data from Centers for Medicare & Medicaid Services") |>
  opt_align_table_header(align = "right") |>
  cols_label(
    patient_survey_star_rating = "Star Rating",
    hcahps_answer_percent = "Answer Percent",
    hcahps_linear_mean_value = "Linear Mean Value"
  )

```

To remove this *missing* data, we will separate the original data set into three different datasets. One for each of our metrics. Although we will only be using the linear mean value dataset, the formatting changes will be applied to all three datasets in order to keep the entire set of data in a similar format.

```{r}
#| label: Separate the data sets

hospital_star_rating <- hospital_1 |> # Star rating is a 1-5 rating of service
  select(
    !c("hcahps_answer_percent", "hcahps_answer_percent_footnote", "hcahps_linear_mean_value" )
  ) |>
  filter(
    !is.na(`patient_survey_star_rating`)
    )


hospital_ans_perc <- hospital_1 |> # Answer percent is percentage of how many times that answer was chosen
  select(
    !c("patient_survey_star_rating", "patient_survey_star_rating_footnote", "hcahps_linear_mean_value" )
  ) |>
  filter(
    !is.na(`hcahps_answer_percent`)
    )


hospital_linear_mean <- hospital_1 |> # linear mean is a standerdization of star rating to be out of 100
  select(
    !c("hcahps_answer_percent", "hcahps_answer_percent_footnote", "patient_survey_star_rating", "patient_survey_star_rating_footnote")
  ) |>
  filter(
    !is.na(`hcahps_linear_mean_value`)
    )

```

Now, the linear mean value data is isolated from the rest.

```{r}
#| label: Isolated linear mean value data

hospital_linear_mean_partial <- head(hospital_linear_mean) |>
  transmute(hcahps_question, 
         hcahps_linear_mean_value
         )

gt(
  hospital_linear_mean_partial,
  rowname_col = "hcahps_question"
) |>
  tab_header(title = "Glimpse of Linear Mean Data") |>
  tab_source_note(source_note = "2024 data from Centers for Medicare & Medicaid Services") |>
  opt_align_table_header(align = "right") |>
  cols_label(
    hcahps_linear_mean_value = "Linear Mean Value"
  )

```

However, in order to further analyze the data, we need to pivot the `question column` to create columns for each individual question.

```{r}
#| label: Pivot the data

hospital_star_rating_pivot <- hospital_star_rating |>
  pivot_wider(id_cols = `facility_id`,
              names_from = `hcahps_question`,
              values_from = `patient_survey_star_rating`) |>
  clean_names() |>
    rename_with(
    \(x) str_remove(x , "_star_rating")
  )


hospital_ans_perc_pivot <- hospital_ans_perc |>
  pivot_wider(id_cols = `facility_id`,
              names_from = `hcahps_question`,
              values_from = `hcahps_answer_percent`) |>
  clean_names()


hospital_linear_mean_pivot <- hospital_linear_mean |>
  pivot_wider(id_cols = `facility_id`,
              names_from = `hcahps_question`,
              values_from = `hcahps_linear_mean_value`) |>
  clean_names() |>
  rename_with(
    \(x) str_remove(x , "_linear_mean_score")
  )

```

```{r}
#| label: Linear mean value data pivoted
#| html-table-processing: none 
#| fig-alt: "A table showing a glimpse of the pivoted linear mean value data."

hospital_linear_mean_pivot_partial <- head(hospital_linear_mean_pivot) |>
  rename("Quiteness" = quietness, 
         "Cleanliness" = cleanliness, 
         "Nurse Communication" = nurse_communication, 
         "Doctor Communication" = doctor_communication, 
         "Staff Responsiveness" = staff_responsiveness, 
         "Communication About Medicines" = communication_about_medicines,
         "Discharge Information" = discharge_information,
         "Care Transition" = care_transition,
         "Overall Rating" = overall_hospital_rating,
         "Recommend Hospital" = recommend_hospital
         )

gt(
  head(hospital_linear_mean_pivot_partial),
  rowname_col = "facility_id"
) |>
  tab_header(title = "Glimpse of Pivoted Linear Mean Data") |>
  tab_source_note(source_note = "2024 data from Centers for Medicare & Medicaid Services") |>
  tab_stubhead(label = "Facility ID") |>
  opt_align_table_header(align = "left")
```

## Exploratory Data Analysis

There are two metrics that can determine a hospitals quality, overall rating and recommendation score. On the survey, individuals were asked to provide an overall rating of the hospital, and a score on how likely they would recommend the hospital. We will use the recommendation score as our indicator of quality since it offers more personalized and nuanced information, but first we need to verify that these to metrics are comparable.

```{r}
#| label: Rating vs Recomend analysis
#| message: false
#| fig-alt: "A plot showing overall hospital rating on the horizontal axis and recommendation score on the vertical axis. Details explained in the text below."

ggplot(
  data = hospital_linear_mean_pivot,
  mapping = aes(x = overall_hospital_rating, y = recommend_hospital)
) +
  geom_point() +
    labs(
    title = "Hostpital Ratings (2024)",
    x = "Overall Hospital Rating",
    y = "Recommendation Score"
  ) +
  theme(
    legend.position = "none",
    plot.title = element_text(
      hjust = 0.5, # center
      face = "bold",
      size = 20
    ),
    axis.title.x = element_text( # sets only x-axis
      size = 15
    ),
    axis.text.x = element_text(
      size = 10
    ),
    axis.title.y = element_text( # sets only y-axis
      size = 15
    ),
    axis.text.y = element_text(
      size = 10
    )
        ) +
  geom_smooth(method = "lm", se = FALSE, color = "red")

```

There is a positive correlation between the `overall hospital rating` and the `recommendation score`. This makes sense since a hospital with a higher rating should be more likely to be recommended. Since these metrics are comparable, we will be using the `recommendation score` as our indicator of quality.

## Modeling

To analyze the data and answer our question, we will create an inferential model using principal component analysis. As described in our design, we will include all components and we will not evaluate model predictions. Therefore, we will not be creating a holdout set.

#### Linear Regression

We start by defining the type of model we want to run, and setting up our workflow.

```{r}
#| label: Set up model and begin workflow

linear_model <- linear_reg(mode = "regression", engine = "lm")

linear_wflow <- workflow() |>
  add_model(linear_model)
```

When setting up the component analysis, we need to remove the `overall hospital ratings`. This is necessary since we have previously shown that they are directly correlated.

```{r}
#| label: Create recipe and commit to workflow

pca_recipe <- recipe(
  recommend_hospital ~ . , data = hospital_linear_mean_pivot
) |>
## ~ . indicates to use all variables in the dataset as predictors besides the response
  update_role(facility_id, new_role = "id") |>
  step_rm(overall_hospital_rating) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_pca(all_predictors(), num_comp = 8)

linear_wflow <- linear_wflow |>
  add_recipe(pca_recipe)
```

Next, we fit the model on our component analysis.

```{r}
#| label: Fit the model and create a table

linear_fit <- fit(linear_wflow, data = hospital_linear_mean_pivot)

```

Now that we have our fitted model, we can take a look at our p-values. We will consider a p-value less than 0.01 to be significant.

```{r}
#| label: Table of coefficients
#| html-table-processing: none 
#| fig-alt: "A table showing p-values and coefficients. Details explained in the text below."


linear_fit_tibble <- tidy(linear_fit) |>
  arrange(p.value)

gt(
  linear_fit_tibble,
  rowname_col = "term"
) |>
  tab_header(title = "Significance of Components") |>
  tab_source_note(source_note = "2024 data from Centers for Medicare & Medicaid Services") |>
  opt_align_table_header(align = "right") |>
  tab_style(
    style = list(
      cell_fill(color = "red", alpha = 0.2),
      cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = c(estimate, p.value),
      rows = p.value <= 1e-2
    )
  ) |>
  cols_move_to_start(p.value) |>
  cols_label(
    p.value = "P-Value",
    estimate = "Coefficient",
    std.error = "Standard Error",
    statistic = "Statistic"
  ) |>
  fmt_scientific(
    columns = c(p.value)
  )
```

As shown in the table, every component except for component number 3 is significant with a p-value less than 0.01. Now that we know which components significantly affect recommendation scores, we now need to find what each component represents.

#### Principal Component Analysis

```{r}
#| label: Using pca for inference

pca_prep <- pca_recipe |>
  prep()

pca_baked <- pca_prep |>
  bake(new_data = NULL)

pca_tidy <- tidy(pca_prep, 4, type = "coef") # tidy step 4 - the PCA step

```

Now that we have the loadings for our component analysis, we can create a graph and interpret each component's meaning.

```{r}
#| label: Plotting with ggplot

pca_tidy |>
  filter(!(component %in% c("PC3"))) |>
  mutate(terms = recode(terms, 
                        Quiteness = "Quietness", 
                        cleanliness = "Cleanliness", 
                        nurse_communication = "Nurse Communication", 
                        doctor_communication = "Doctor Communication", 
                        staff_responsiveness = "Staff Responsivness", 
                        communication_about_medicines = "Communication About Medicines",
                        discharge_information = "Discharge Information",
                        care_transition = "Care Transition"
                        )) |>
  ggplot(aes(x = value, y = terms, fill = abs(value))) +
  geom_col() +
  labs(
    title = "Significant Principal Component \nAnalysis Loadings",
    y = "Terms",
    x = "Values"
  ) +
  theme(
    legend.position = "none",
    plot.title = element_text(
      hjust = 0.5, # center
      face = "bold",
      size = 20 # guessing this is okay for title
    ),
    axis.title.x = element_text( # sets only x-axis
      size = 15
    ),
    axis.text.x = element_text(
      size = 10
    ),
    axis.title.y = element_text( # sets only y-axis
      size = 15
    ),
    axis.text.y = element_text(
      size = 10
    ),
    legend.title = element_text( # legend title
      size = 20
    ),
    legend.text = element_text( # Approved vs Not Approved
      size = 16
    )
        ) +
  scale_fill_gradient(low = "black", high = "red") +
  facet_wrap(vars(component), nrow = 2)

```

Now that we have the graphs of each component, we can interpret their meaning.

Each component represents a specific trend in our data. Component 1 represents the most significant trend, that high ratings affect recommendation scores, while each subsequent component represents a less significant trend. Looking back at our significance of components table, we can determine if the trend, in relation to recomendation scores, is positive or negative by the sign of the coefficients.

| Component             | Trends                                                                                                   |
|--------------------------|----------------------------------------------|
| Principal Component 1 | Highly rated (+)                                                                                         |
| Principal Component 2 | Quiet and clean vs discharge information (+)                                                             |
| Principal Component 4 | Doctor communication vs quietness and discharge information (-)                                          |
| Principal Component 5 | Doctor communication, discharge information, and care transition vs Staff responsiveness (-)             |
| Principal Component 6 | Staff responsiveness, nurse communication, and doctor communication vs communication about medicines (-) |
| Principal Component 7 | Care transition vs doctor communication and discharge information (-)                                    |
| Principal Component 8 | Staff responsiveness and care transition vs nurse communication (+)                                      |

## Conclusion

Our analysis has shown us that these principle components are the factors that contribute to a change in a hospitals recommendation score. For example, if all other components are held constant, a change in principal component 2 will significantly affect a hospitals recommendation score. It is important to note that each subsequent component accounts for less of the overall variance of our data. This means that in descending order, when accurately interpreted, principal component 1 will account for the most fluctuation in our data, and principal component 8 will account for the least. This analysis provides insights on what people value from hospitals, and what hospitals can do to provide better care. According to this analysis, the most valued aspects of hospitals are overall competency with some focus on quietness, cleanliness, and discharge information.

#### Limitations and Ethical Concerns

There are a few limitations and ethical concerns that should be mentioned. These insights should not be used as a means of justification for hospitals to de-prioritize certain aspects of care in hopes of a better recommendation score. Not only would this be ineffective considering principle component 1, it would also have the potential to actively harm individuals. Some of our components had a negative correlation with recommendations scores. This negative correlation does not mean that we should reduce efforts in those variables. Take principle component 7 for example. This component represents care transition scores vs doctor communication and discharge information scores. What this negative trend represents is how, when all other factors are held constant, prioritizing care transition over doctor communication and discharge information, and vice versa, negatively impacts a persons experience. Another thing to consider is the reliability of the data. When people go to the hospital, the last thing on their mind is filling out a survey. This could lead to rushing through the survey, and poor recollection about their stay.
