---
title: "Encelia Flower Model Selection"
format: html
editor: visual
---

## Motivation and Context

```{r}
#| label: do this first
#| echo: false
#| message: false

# change this to whatever you renamed the .qmd file to; then delete this comment
here::i_am("Project-Model-Selection-Encelia.qmd")
```

Southern California is home to two native species in the *Encelia* genus, *californica* and *farinosa*. *Encelia californica* is found in more coastal regions and *Encelia farinosa* is found in more inland desert regions.

It has become common in Orange County to plant *farinosa* near roadsides and in other areas where *californica* is native. The two plants hybridize easily, so it is not uncommon to see in the wild a plant that has some characteristics of *californica* and some characteristics of *farinosa*.

The Fullerton Arboretum is home to both species. Our goal is to build a model that can "discriminate" between *californica* and *farinosa*. Such models might later be used by botanists to investigate how a putative hybrid can be discriminated from the two parent species.

## Main Objective

The goal of this project is to create a few different classification models that predict if a flower is *californica* or *farinosa*. After these models have been made, we will perform model selection on them to determine which model is "best".

## Packages Used In This Analysis

```{r}
#| label: load packages
#| message: false
#| warning: false

library(here)
library(readr)
library(ggplot2)
library(dplyr)
library(rsample)
library(purrr)
library(yardstick)
library(tidyr)
library(broom)
library(patchwork)
library(gt)
```

| Package                                           | Use                                                                       |
|-----------------------------|-------------------------------------------|
| [here](https://github.com/jennybc/here_here)      | to easily load and save data                                              |
| [readr](https://readr.tidyverse.org/)             | to import the CSV file data                                               |
| [dplyr](https://dplyr.tidyverse.org/)             | to massage and summarize data                                             |
| [ggplot2](https://ggplot2.tidyverse.org/)         | to create nice-looking and informative graphs                             |
| [rsample](https://rsample.tidymodels.org/)        | to split data into training and test sets                                 |
| [purrr](https://purrr.tidyverse.org)              | to run the cross-validation                                               |
| [yardstick](https://yardstick.tidymodels.org)     | to evalute the accuracy of the models                                     |
| [tidyr](https://tidyr.tidyverse.org)              | to "pivot" the predictions data frame so that each row represents 1 model |
| [broom](https://broom.tidymodels.org/)            | to create tibbles                                                         |
| [patchwork](https://patchwork.data-imaginist.com) | to graph multiple graphs at once                                          |
| [gt](https://gt.rstudio.com/)                     | to create tables                                                          |

## Design and Data Collection

This data was collected during an in class trip to the Fullerton Arboretum. Students decided collectively on what data to collect, then broke into groups to collect this data. The class decide to measure the number of rays, ray length (overall diameter), disk length (disk diameter), and stem length.

![](Flower_Description.png)

There were some limitations to our data collection method. One major difficulty was that since we did not designate sections of the Arboretum for each group to measure, flowers most likely got measured multiple times. Another limitation would be that each student could read their ruler slightly differently, leading to a variation in the data.

## Training-Test Split

There isn't much data massaging we need to do here, because we were very deliberate about how we set up our data sheet and how we recorded the data on it.

At the end of this section, you should write code to randomly split the Encelia data into a training and test set and explain why a training and test set are useful/necessary for this objective.

```{r}
#| label: Import data
#| warning: false
#| message: false
#| echo: false

encelia <- read_csv(here::here("Data/Encelia Classification Data Collection - Sheet1.csv"))

```

We will create a training and test set of our data. This will be useful in our modeling step by allowing us to test the effectiveness of our models by predicting on our test set. Since we will know the actual species vs the predicted species, we can evaluate how well a model performs.

```{r}
#| label: Training and test split

encelia <- encelia |>
  mutate(
    Species = as.factor(Species),
    Species = recode(Species, `C` = 'Californica', `F` = 'Farinosa')
  ) 
  

set.seed(69)

encelia_split <- initial_split(
  encelia,
  strata = Species,
  prop = 0.80
)

encelia_train <- training(encelia_split) 
encelia_test <- testing(encelia_split)

```

## Exploratory Data Analysis

For our exploratory data analysis, we will be creating four different graphs. Each graph will group by the species and display one of our measurements.

First, we will look at the number of rays.

```{r}
#| label: Graph of number of rays grouped by species

ggplot(
  data = encelia_train,
  mapping = aes(x = number_rays, y = Species)
) +
  geom_jitter(height = 0.1) +
  labs(
    title = "Number of Rays by Species",
    x = "Number of Rays",
    y = ""
  ) +
  theme(
    legend.position = "none",
    plot.title = element_text(
      hjust = 0.5, # center
      face = "bold",
      size = 20
    ),
    axis.title.x = element_text( # sets only x-axis
      size = 15
    ),
    axis.text.x = element_text(
      size = 12
    ),
    axis.title.y = element_text( # sets only y-axis
      size = 15
    ),
    axis.text.y = element_text(
      size = 15
    )
        )
```

As shown above, *farinosa* seems to have less variance in amount of rays compared to *californica*. This difference could lead to ray numbers being a good predictor variable for *californica*.

Next, we will graph disk length.

```{r}
#| label: Graph of disk diameter grouped by species

ggplot(
  data = encelia_train,
  mapping = aes(x = disk_diameter, y = Species)
) +
  geom_jitter(height = 0.1) +
    labs(
    title = "Disk Diameter by Species",
    x = "Disk Diameter (cm)",
    y = ""
  ) +
  theme(
    legend.position = "none",
    plot.title = element_text(
      hjust = 0.5, # center
      face = "bold",
      size = 20
    ),
    axis.title.x = element_text( # sets only x-axis
      size = 15
    ),
    axis.text.x = element_text(
      size = 12
    ),
    axis.title.y = element_text( # sets only y-axis
      size = 15
    ),
    axis.text.y = element_text(
      size = 15
    )
        )
```

As we can see, disk diameter between *californica* and *farinosa* seems to have similar variance. However, both species are centered in different places, which means that this variable could be a good predictor between species.

Now, we will look at ray length.

```{r}
#| label: Graph of ray diameter grouped by species

ggplot(
  data = encelia_train,
  mapping = aes(x = ray_diameter, y = Species)
) +
  geom_jitter(height = 0.1) +
    labs(
    title = "Ray Diameter by Species",
    x = "Ray Diameter (cm)",
    y = ""
  ) +
  theme(
    legend.position = "none",
    plot.title = element_text(
      hjust = 0.5, # center
      face = "bold",
      size = 20
    ),
    axis.title.x = element_text( # sets only x-axis
      size = 15
    ),
    axis.text.x = element_text(
      size = 12
    ),
    axis.title.y = element_text( # sets only y-axis
      size = 15
    ),
    axis.text.y = element_text(
      size = 15
    )
        )
```

Ray diameter seems to be similar to ray number. Both have *farinosa* with a smaller variance with an overlap between the two species.

Finally, we will graph stem length.

```{r}
#| label: Graph of stem length grouped by species
#| warning: false

ggplot(
  data = encelia_train,
  mapping = aes(x = stem_length, y = Species)
) +
  geom_jitter(height = 0.1) +
    labs(
    title = "Stem Length by Species",
    x = "Stem Length (cm)",
    y = ""
  ) +
  theme(
    legend.position = "none",
    plot.title = element_text(
      hjust = 0.5, # center
      face = "bold",
      size = 20
    ),
    axis.title.x = element_text( # sets only x-axis
      size = 15
    ),
    axis.text.x = element_text(
      size = 12
    ),
    axis.title.y = element_text( # sets only y-axis
      size = 15
    ),
    axis.text.y = element_text(
      size = 15
    )
        )
```

As shown, *farinosa* has a small variance and is offset from *californica*. This variable would most likely be a good predictor between species.

## Modeling

We will make 4 different models, 1 of which will be the null model. We will then perform cross-validation to select a "best" model. We will be making these models with logistic regression. Logistic regression is a statistical model that models the log-odds of an event as a linear combination of one or more independent variables.

I decided to make a model with all the variables (model 1), just ray data (model 2), just lengths (model 3), and a null model (model 4). I decided to make these models since these models pair data that seem like they could work in conjunction with each other.

```{r}
#| label: Model with all variables

encelia_split <- encelia_train |>
  vfold_cv(
  v = 10, # 10 folds
  repeats = 1 #make 1 prediction for each obs.
)

encelia_prediction <- function(split){
  # Step 1: create the training and validation sets
  train <- analysis(split)
  valid <- assessment(split)
  
  # Step 2: fit model(s) on training set
  glm1 <- glm(
    Species ~ number_rays + disk_diameter + ray_diameter + stem_length,
    data = train,
    family = "binomial"
  )
  
  glm2 <- glm(
    Species ~ number_rays + ray_diameter,
    data = train,
    family = "binomial"
  )
  
  glm3 <- glm(
    Species ~ disk_diameter + ray_diameter + stem_length,
    data = train,
    family = "binomial"
  )
  
  glmnull <- glm(
    Species ~ 1,
    data = train,
    family = "binomial"
  )
  
  
  # Step 3: predict on validation set
  valid_pred <- valid |>
    mutate(
      pred1 = predict(glm1, newdata = valid, type = "response"),
      pred2 = predict(glm2, newdata = valid, type = "response"),
      pred3 = predict(glm3, newdata = valid, type = "response"),
      prednull = predict(glmnull, newdata = valid, type = "response")
    )
  
  return(valid_pred)
}

```

Now we map the predictions to a data frame.

```{r}
#| label: Map predictions
#| warning: false

mapped_predictions <- map(
  encelia_split$splits,
  encelia_prediction
)

```

```{r}
#| label: Convert mappings into a data frame

mapped_pred_df <- bind_rows(
  mapped_predictions,
  .id = "Fold"
)

```

Next, we check which species we are predicting.

```{r}
contrasts(encelia_train$Species)
```

Since *farinosa* is a 1, we are predicting the probability of *farinosa*.

In order to decide which model to use, we need to compute the brier scores. The brier score measures the accuracy of our predictions by calculating the mean squared difference between our predicted probability and our actual outcome. Since we are calculating mean squared difference, lower brier scores are preferred, and we expect a score of 0.25 for our null model.

```{r}
#| label: all predictions

all_preds <- mapped_pred_df |>
  pivot_longer(
    cols = starts_with("pred"),
    names_to = "model",
    values_to = "pred"
  )

brier_scores <- all_preds |>
  mutate(
    pred_californica = 1 - pred
  ) |>
  group_by(model, Fold) |>
  brier_class(
    truth = Species,
    pred_californica # since californica is the first level, we must pass brier class the predicted prob. of californica
  ) |>
  ungroup() |>
  group_by(model) |>
  summarise(
    mean_brier = mean(.estimate),
    se_brier = sd(.estimate)/sqrt(5)
  )

brier_scores <- brier_scores |>
  mutate(model = c("Model 1", "Model 2", "Model 3", "Null Model"))


gt(
  brier_scores,
  rowname_col = "model"
) |>
  tab_header(title = "Brier Scores") |>
  tab_source_note(source_note = "2025 data from Class Fieldtrip") |>
  opt_align_table_header(align = "right") |>
  tab_style(
    style = list(
      cell_fill(color = "red", alpha = 0.2),
      cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = c(model, mean_brier),
      rows = mean_brier <= min(mean_brier) + se_brier
    )
  ) |>
    cols_label(
    mean_brier = "Mean Brier Score",
    se_brier = "Standard Error"
  )
```

Model 1 has our lowest mean brier score. Since model 3 has a mean brier score within one standard deviation from model 1, it is also a contender for our "best" model. Since model 3 is a simpler model, we will select this as our "best" model. Model 3 is simpler since it uses less predictor variables. Now, we will evaluate this model to see how well it performs by using a ROC curve.

```{r}
#| label: Best model

glm3 <- glm(
  Species ~ disk_diameter + ray_diameter + stem_length,
  data = encelia_train,
  family = "binomial"
)

species_final_preds <- glm3 |>
  augment(newdata = encelia_test,
          type.predict = "response")

species_predictions <- species_final_preds |>
  mutate(
    predicted_class = if_else(
      .fitted > 0.5, # more likely to have AD than not
      "Farinosa", # value if TRUE
      "Californica" # value if FALSE
    ) |>
      as.factor() |> # convert to factor
      relevel(ref = "Californica") # define reference level
  )


```

```{r}
#| label: Final model evaluation

roc_df <- species_final_preds |>
  roc_curve(
  truth = Species,
  .fitted,
  event_level = "second"
)

autoplot(roc_df) +
  labs(
    title = "ROC Curve",
    x = "Specificity",
    y = "Sensitivity"
  ) +
    theme(
    legend.position = "none",
    plot.title = element_text(
      hjust = 0.5, # center
      face = "bold",
      size = 20
    ),
    axis.title.x = element_text( # sets only x-axis
      size = 15
    ),
    axis.text.x = element_text(
      size = 12
    ),
    axis.title.y = element_text( # sets only y-axis
      size = 15
    ),
    axis.text.y = element_text(
      size = 15
    )
        )

species_roc_auc <- species_final_preds |>
  roc_auc(
  truth = Species,
  .fitted,
  event_level = "second"
  )

species_roc_auc$.estimate

```

This ROC curve is a very good sign. An area under the curve of 1 would mean perfect predictive performance. This curve has an area under the curve of 0.97. This is a very good score, indicating our model is very effective.

## Insights

Lets take a look at some incorrect predictions that the model made.

```{r}
#| label: Incorrect predictions

species_pred_false <- species_predictions |> 
  select(!c(".fitted")
         ) |>
  filter(
    Species != predicted_class
  )


gt(
  species_pred_false,
  rowname_col = "Species"
) |>
  tab_header(title = "Incorrect Predictions") |>
  tab_source_note(source_note = "2025 data from Class Fieldtrip") |>
  opt_align_table_header(align = "right") |>
  cols_move_to_start(predicted_class) |>
  cols_label(
    number_rays = "Number of Rays",
    disk_diameter = "Disk Diameter",
    ray_diameter = "Ray Diameter",
    stem_length = "Stem Length",
    predicted_class = "Prediction"
  )
```

Why were these flowers predicted incorrectly? For these flowers, the most likely cause would be the fact that there is a lot of overlap between the two species. The mean for each *farinosa* data point lies within the bounds of *californica*. What this means is that the model can predict *californica* with a lot of certainty, but predicting *farinosa* is much harder.
